{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T20:26:08.873563Z",
     "start_time": "2020-12-30T20:26:08.835048Z"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "using device: GeForce GTX 1060 3GB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torchaudio\n",
    "from torchaudio import transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from pydub import AudioSegment\n",
    "torchaudio.USE_SOUNDFILE_LEGACY_INTERFACE = False\n",
    "\n",
    "np.random.seed(seed:=69)\n",
    "torch.manual_seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "current_device = torch.cuda.get_device_name(0) if torch.cuda.device_count() > 0 else 'cpu'\n",
    "print(f'using device: {current_device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T20:23:03.166443Z",
     "start_time": "2020-12-30T20:23:03.163425Z"
    }
   },
   "outputs": [],
   "source": [
    "input_path = './input/cleaned/'\n",
    "output_path = './input/cleaned/output/'\n",
    "sample_rate = 44100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T20:23:03.682778Z",
     "start_time": "2020-12-30T20:23:03.637898Z"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "missing values: 0\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                               input  \\\n",
       "0  ./input/cleaned/x/12 Comics You Need to See - ...   \n",
       "1  ./input/cleaned/x/12 Comics You Need to See - ...   \n",
       "2  ./input/cleaned/x/12 Comics You Need to See - ...   \n",
       "3  ./input/cleaned/x/12 Comics You Need to See - ...   \n",
       "4  ./input/cleaned/x/12 Comics You Need to See - ...   \n",
       "\n",
       "                                              target  \n",
       "0  ./input/cleaned/y/12 Comics You Need to See - ...  \n",
       "1  ./input/cleaned/y/12 Comics You Need to See - ...  \n",
       "2  ./input/cleaned/y/12 Comics You Need to See - ...  \n",
       "3  ./input/cleaned/y/12 Comics You Need to See - ...  \n",
       "4  ./input/cleaned/y/12 Comics You Need to See - ...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>input</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>./input/cleaned/x/12 Comics You Need to See - ...</td>\n      <td>./input/cleaned/y/12 Comics You Need to See - ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>./input/cleaned/x/12 Comics You Need to See - ...</td>\n      <td>./input/cleaned/y/12 Comics You Need to See - ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>./input/cleaned/x/12 Comics You Need to See - ...</td>\n      <td>./input/cleaned/y/12 Comics You Need to See - ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>./input/cleaned/x/12 Comics You Need to See - ...</td>\n      <td>./input/cleaned/y/12 Comics You Need to See - ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>./input/cleaned/x/12 Comics You Need to See - ...</td>\n      <td>./input/cleaned/y/12 Comics You Need to See - ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "input_li = pd.Series([input_path + 'x/' + i for i in os.listdir(input_path + 'x/')], dtype=str)\n",
    "# targets have the exact same name, but are in the y/ folder, so to ensure that everything is in the \n",
    "# proper order, list through the input directory, but link to the y/ directory\n",
    "target_li = pd.Series([input_path + 'y/' + i for i in os.listdir(input_path + 'x/')], dtype=str)\n",
    "# table = pd.DataFrame(data=[X, y], columns=['input', 'target'])\n",
    "# table.head()\n",
    "df = pd.DataFrame(data={'input': input_li, 'target': target_li})\n",
    "print(f'missing values: {df.isna().any().sum()}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T20:23:04.124462Z",
     "start_time": "2020-12-30T20:23:04.105486Z"
    }
   },
   "outputs": [],
   "source": [
    "class AudioDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, input_path, transform=None):\n",
    "        self.input_path = input_path\n",
    "        # use a root path that branches into x/ and y/ directories\n",
    "        input_li = pd.Series([input_path + 'x/' + i for i in os.listdir(input_path + 'x/')], dtype=str)\n",
    "        # targets have the exact same name, but are in the y/ folder, so to ensure that everything is in the \n",
    "        # proper order, list through the input directory, but link to the y/ directory\n",
    "        target_li = pd.Series([input_path + 'y/' + i for i in os.listdir(input_path + 'x/')], dtype=str)\n",
    "        df = pd.DataFrame(data={'input': input_li, 'target': target_li})\n",
    "        self.df = df.sample(frac=1, random_state=seed)\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        x = self.df['input'].iloc[idx]\n",
    "        x, _ = torchaudio.load(x)\n",
    "        y = self.df['target'].iloc[idx]\n",
    "        y, _ = torchaudio.load(y)\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "            y = self.transform(y)\n",
    "        return x, y\n",
    "    \n",
    "    def random(self):\n",
    "        idx = random.randint(0, len(self.df))\n",
    "        return self.__getitem__(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T20:23:04.597777Z",
     "start_time": "2020-12-30T20:23:04.557764Z"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "num samples: 30984\n2 44100\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[-0.1303, -0.1345, -0.1401,  ...,  0.0357,  0.0464,  0.0559],\n",
       "         [ 0.0567,  0.0561,  0.0545,  ...,  0.1372,  0.1462,  0.1501]]),\n",
       " tensor([[-0.0445, -0.0443, -0.0428,  ...,  0.0082,  0.0010, -0.0049],\n",
       "         [ 0.0732,  0.0727,  0.0716,  ...,  0.0344,  0.0327,  0.0284]]))"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "data = AudioDataset(input_path=input_path)\n",
    "print(f'num samples: {len(data)}')\n",
    "x, y = data[0]\n",
    "input_shape = x.shape\n",
    "flat_feats = input_shape[0] * input_shape[1] \n",
    "print(input_shape[0], input_shape[1])\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T20:23:05.052440Z",
     "start_time": "2020-12-30T20:23:05.041441Z"
    }
   },
   "outputs": [],
   "source": [
    "# loss function\n",
    "def mse(output:torch.Tensor, label:torch.Tensor):\n",
    "    return torch.mean((output - label) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T20:23:05.588657Z",
     "start_time": "2020-12-30T20:23:05.580678Z"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(0.0049)"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "mse(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T20:23:06.142636Z",
     "start_time": "2020-12-30T20:23:06.134622Z"
    }
   },
   "outputs": [],
   "source": [
    "# build another loss function, which is based on:\n",
    "# https://openaccess.thecvf.com/content_CVPR_2019/papers/Yuan_Signal-To-Noise_Ratio_A_Robust_Distance_Metric_for_Deep_Metric_Learning_CVPR_2019_paper.pdf\n",
    "# tinyurl:\n",
    "# https://tinyurl.com/yclop5na\n",
    "# this is our implementation\n",
    "class PSNR:\n",
    "    \"\"\"Peak Signal to Noise Ratio\n",
    "    output and target have range [0, 255]\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.name = \"PSNR\"\n",
    "\n",
    "    @staticmethod\n",
    "    def __call__(output, target):\n",
    "        mse = torch.mean((output - target) ** 2)\n",
    "        return 20 * torch.log10(255.0 / torch.sqrt(mse))\n",
    "\n",
    "class audio_PSNR:\n",
    "    \"\"\"Peak Signal to Noise Ratio\n",
    "    output and target have range [-1, 1]\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.name = \"audio PSNR\"\n",
    "\n",
    "    @staticmethod\n",
    "    def __call__(output, target):\n",
    "        mse = torch.mean((output - target) ** 2)\n",
    "        return 20 * torch.log10(1.0 / torch.sqrt(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T20:23:06.854828Z",
     "start_time": "2020-12-30T20:23:06.833884Z"
    }
   },
   "outputs": [],
   "source": [
    "class FC_Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.input_shape = self.num_flat_features(x)\n",
    "        super(FC_Net, self).__init__()\n",
    "#         self.conv2d = nn.Conv2d()\n",
    "    \n",
    "    def reshape(self, x):\n",
    "        return torch.unsqueeze(x, 0)\n",
    "    \n",
    "    def fc1(self, x):\n",
    "        x = nn.Linear(self.input_shape, self.input_shape)\n",
    "        x = f.relu(x)\n",
    "\n",
    "    def melspectrogram(self, x):\n",
    "        melspectrogram_transform = transforms.MelSpectrogram(\n",
    "        sample_rate=44100, n_mels=128\n",
    "        )\n",
    "        melspectrogram_db_transform = transforms.AmplitudeToDB()\n",
    "    \n",
    "    def num_flat_features(self, x) -> int:\n",
    "        size = x.size()[1:] # all dims except batch dim\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return int(num_features)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.reshape(x)\n",
    "        x = f.relu(self.fc1(x))\n",
    "#         x = f.relu(self.fc3(x))\n",
    "        x = torch.reshape(x, self.input_shape)\n",
    "        x = nn.Linear(self.input_shape, self.input_shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T20:23:07.404847Z",
     "start_time": "2020-12-30T20:23:07.389916Z"
    }
   },
   "outputs": [],
   "source": [
    "net = FC_Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T20:23:08.159917Z",
     "start_time": "2020-12-30T20:23:08.144958Z"
    }
   },
   "outputs": [],
   "source": [
    "# melspectogram_transform = \\\n",
    "#     torchaudio.transforms.MelSpectrogram(\n",
    "#     sample_rate=sample_rate, n_mels=128)\n",
    "# melspectogram_db_transform = torchaudio.transforms.AmplitudeToDB()\n",
    "\n",
    "# melspectogram = melspectogram_transform(audio)\n",
    "# plt.figure()\n",
    "# plt.imshow(melspectogram.squeeze().numpy(), cmap='hot')\n",
    "    \n",
    "# melspectogram_db=melspectogram_db_transform(melspectogram)\n",
    "# plt.figure()\n",
    "# plt.imshow(melspectogram_db.squeeze().numpy(), cmap='hot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T20:26:56.184851Z",
     "start_time": "2020-12-30T20:26:56.156744Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}