{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-29T18:43:03.910236Z",
     "start_time": "2020-12-29T18:43:03.898267Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: GeForce GTX 1060 3GB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "from torchaudio import transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchaudio\n",
    "torchaudio.USE_SOUNDFILE_LEGACY_INTERFACE = False\n",
    "\n",
    "np.random.seed(seed:=69)\n",
    "torch.manual_seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "current_device = torch.cuda.get_device_name(0) if torch.cuda.device_count() > 0 else 'cpu'\n",
    "print(f'using device: {current_device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-29T18:28:08.515741Z",
     "start_time": "2020-12-29T18:28:08.498788Z"
    }
   },
   "outputs": [],
   "source": [
    "input_path = './input/cleaned/'\n",
    "output_path = './input/cleaned/output/'\n",
    "sample_rate = 44100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-29T18:28:08.949292Z",
     "start_time": "2020-12-29T18:28:08.912390Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing values: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./input/cleaned/x/12 Comics You Need to See - ...</td>\n",
       "      <td>./input/cleaned/y/12 Comics You Need to See - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./input/cleaned/x/12 Comics You Need to See - ...</td>\n",
       "      <td>./input/cleaned/y/12 Comics You Need to See - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./input/cleaned/x/12 Comics You Need to See - ...</td>\n",
       "      <td>./input/cleaned/y/12 Comics You Need to See - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./input/cleaned/x/12 Comics You Need to See - ...</td>\n",
       "      <td>./input/cleaned/y/12 Comics You Need to See - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./input/cleaned/x/12 Comics You Need to See - ...</td>\n",
       "      <td>./input/cleaned/y/12 Comics You Need to See - ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               input  \\\n",
       "0  ./input/cleaned/x/12 Comics You Need to See - ...   \n",
       "1  ./input/cleaned/x/12 Comics You Need to See - ...   \n",
       "2  ./input/cleaned/x/12 Comics You Need to See - ...   \n",
       "3  ./input/cleaned/x/12 Comics You Need to See - ...   \n",
       "4  ./input/cleaned/x/12 Comics You Need to See - ...   \n",
       "\n",
       "                                              target  \n",
       "0  ./input/cleaned/y/12 Comics You Need to See - ...  \n",
       "1  ./input/cleaned/y/12 Comics You Need to See - ...  \n",
       "2  ./input/cleaned/y/12 Comics You Need to See - ...  \n",
       "3  ./input/cleaned/y/12 Comics You Need to See - ...  \n",
       "4  ./input/cleaned/y/12 Comics You Need to See - ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_li = pd.Series([input_path + 'x/' + i for i in os.listdir(input_path + 'x/')], dtype=str)\n",
    "# targets have the exact same name, but are in the y/ folder, so to ensure that everything is in the \n",
    "# proper order, list through the input directory, but link to the y/ directory\n",
    "target_li = pd.Series([input_path + 'y/' + i for i in os.listdir(input_path + 'x/')], dtype=str)\n",
    "# table = pd.DataFrame(data=[X, y], columns=['input', 'target'])\n",
    "# table.head()\n",
    "df = pd.DataFrame(data={'input': input_li, 'target': target_li})\n",
    "print(f'missing values: {df.isna().any().sum()}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-29T18:28:09.230364Z",
     "start_time": "2020-12-29T18:28:09.213435Z"
    }
   },
   "outputs": [],
   "source": [
    "class AudioDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, input_path, transform=None):\n",
    "        self.input_path = input_path\n",
    "        # use a root path that branches into x/ and y/ directories\n",
    "        input_li = pd.Series([input_path + 'x/' + i for i in os.listdir(input_path + 'x/')], dtype=str)\n",
    "        # targets have the exact same name, but are in the y/ folder, so to ensure that everything is in the \n",
    "        # proper order, list through the input directory, but link to the y/ directory\n",
    "        target_li = pd.Series([input_path + 'y/' + i for i in os.listdir(input_path + 'x/')], dtype=str)\n",
    "        df = pd.DataFrame(data={'input': input_li, 'target': target_li})\n",
    "        self.df = df.sample(frac=1, random_state=seed)\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        x = self.df['input'].iloc[idx]\n",
    "        x, _ = torchaudio.load(x)\n",
    "        y = self.df['target'].iloc[idx]\n",
    "        y, _ = torchaudio.load(y)\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "            y = self.transform(y)\n",
    "        return x, y\n",
    "    \n",
    "    def random(self):\n",
    "        idx = random.randint(0, len(self.df))\n",
    "        return self.__getitem__(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-29T18:43:56.855478Z",
     "start_time": "2020-12-29T18:43:56.815528Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num samples: 2144\n",
      "2 1323000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.1151,  0.1110,  0.1024,  ..., -0.2160, -0.2664, -0.3035],\n",
       "         [ 0.0180,  0.0130,  0.0066,  ..., -0.1551, -0.1982, -0.2359]]),\n",
       " tensor([[ 0.0163,  0.0098,  0.0037,  ..., -0.1633, -0.1965, -0.2296],\n",
       "         [-0.0075, -0.0092, -0.0106,  ..., -0.1255, -0.1577, -0.1906]]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = AudioDataset(input_path=input_path)\n",
    "print(f'num samples: {len(data)}')\n",
    "x, y = data[0]\n",
    "input_shape = x.shape\n",
    "flat_feats = input_shape[0] * input_shape[1] \n",
    "print(input_shape[0], input_shape[1])\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-29T18:28:10.014866Z",
     "start_time": "2020-12-29T18:28:09.998910Z"
    }
   },
   "outputs": [],
   "source": [
    "# loss function\n",
    "def mse(output:torch.Tensor, label:torch.Tensor):\n",
    "    return torch.mean((output - label) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-29T18:28:10.440384Z",
     "start_time": "2020-12-29T18:28:10.421463Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0043)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-29T18:28:10.913453Z",
     "start_time": "2020-12-29T18:28:10.902484Z"
    }
   },
   "outputs": [],
   "source": [
    "# build another loss function, which is based on:\n",
    "# https://openaccess.thecvf.com/content_CVPR_2019/papers/Yuan_Signal-To-Noise_Ratio_A_Robust_Distance_Metric_for_Deep_Metric_Learning_CVPR_2019_paper.pdf\n",
    "# tinyurl:\n",
    "# https://tinyurl.com/yclop5na\n",
    "# this is our implementation\n",
    "class PSNR:\n",
    "    \"\"\"Peak Signal to Noise Ratio\n",
    "    output and target have range [0, 255]\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.name = \"PSNR\"\n",
    "\n",
    "    @staticmethod\n",
    "    def __call__(output, target):\n",
    "        mse = torch.mean((output - target) ** 2)\n",
    "        return 20 * torch.log10(255.0 / torch.sqrt(mse))\n",
    "\n",
    "class audio_PSNR:\n",
    "    \"\"\"Peak Signal to Noise Ratio\n",
    "    output and target have range [-1, 1]\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.name = \"audio PSNR\"\n",
    "\n",
    "    @staticmethod\n",
    "    def __call__(output, target):\n",
    "        mse = torch.mean((output - target) ** 2)\n",
    "        return 20 * torch.log10(1.0 / torch.sqrt(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-29T18:30:18.200999Z",
     "start_time": "2020-12-29T18:30:18.185073Z"
    }
   },
   "outputs": [],
   "source": [
    "class FC_Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.input_shape = self.num_flat_features(x)\n",
    "        super(FC_Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(flat_feats, flat_feats * 2)\n",
    "        self.fc2 = nn.Linear((flat_feats * 2, flat_feats * 2))\n",
    "        self.fc3 = nn.Linear((flat_feats * 2, input_shape))\n",
    "    \n",
    "    def flatten(self, x):\n",
    "        return torch.flatten(x)\n",
    "    \n",
    "    def melspectrogram(self, x):\n",
    "        melspectrogram_transform = transforms.MelSpectrogram(\n",
    "        sample_rate=44100, n_mels=128\n",
    "        )\n",
    "        melspectrogram_db_transform = transforms.AmplitudeToDB()\n",
    "    \n",
    "    def num_flat_features(self, x) -> int:\n",
    "        size = x.size()[1:] # all dims except batch dim\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return int(num_features)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = f.relu(self.fc1(x))\n",
    "#         x = f.relu(self.fc3(x))\n",
    "        x = torch.reshape(x, self.input_shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-29T18:30:18.701049Z",
     "start_time": "2020-12-29T18:30:18.587355Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at ..\\c10\\core\\CPUAllocator.cpp:73] data. DefaultCPUAllocator: not enough memory: you tried to allocate 56010528000000 bytes. Buy new RAM!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-bf5886e03c60>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFC_Net\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-18-788ce4122c52>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_flat_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFC_Net\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflat_feats\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflat_feats\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflat_feats\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflat_feats\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflat_feats\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, in_features, out_features, bias)\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0min_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0min_features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mout_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mout_features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mParameter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0min_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mParameter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at ..\\c10\\core\\CPUAllocator.cpp:73] data. DefaultCPUAllocator: not enough memory: you tried to allocate 56010528000000 bytes. Buy new RAM!"
     ]
    }
   ],
   "source": [
    "net = FC_Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-29T03:48:15.109198Z",
     "start_time": "2020-12-29T03:48:15.092243Z"
    }
   },
   "outputs": [],
   "source": [
    "# melspectogram_transform = \\\n",
    "#     torchaudio.transforms.MelSpectrogram(\n",
    "#     sample_rate=sample_rate, n_mels=128)\n",
    "# melspectogram_db_transform = torchaudio.transforms.AmplitudeToDB()\n",
    "\n",
    "# melspectogram = melspectogram_transform(audio)\n",
    "# plt.figure()\n",
    "# plt.imshow(melspectogram.squeeze().numpy(), cmap='hot')\n",
    "    \n",
    "# melspectogram_db=melspectogram_db_transform(melspectogram)\n",
    "# plt.figure()\n",
    "# plt.imshow(melspectogram_db.squeeze().numpy(), cmap='hot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-29T19:50:29.463780Z",
     "start_time": "2020-12-29T19:50:29.362198Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "661500\n"
     ]
    }
   ],
   "source": [
    "x, y = data[0]\n",
    "x = torch.flatten(x)\n",
    "# x = x @ torch.randn(x.shape[0], 6)\n",
    "for i in range(661500, x.shape[0], x.shape[0] / 50):\n",
    "    try:\n",
    "        p = torch.randn(x.shape[0], i)\n",
    "        del p\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-29T19:39:37.896317Z",
     "start_time": "2020-12-29T19:39:37.889334Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
