{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-25T16:51:05.278753Z",
     "start_time": "2020-12-25T16:51:05.253845Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: GeForce GTX 1060 3GB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torchaudio import transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchaudio\n",
    "torchaudio.USE_SOUNDFILE_LEGACY_INTERFACE = False\n",
    "\n",
    "np.random.seed(seed:=69)\n",
    "torch.manual_seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "current_device = torch.cuda.get_device_name(0) if torch.cuda.device_count() > 0 else 'cpu'\n",
    "print(f'using device: {current_device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-25T16:51:06.118819Z",
     "start_time": "2020-12-25T16:51:06.107846Z"
    }
   },
   "outputs": [],
   "source": [
    "input_path = './input/cleaned/'\n",
    "output_path = './input/cleaned/output/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-25T16:51:06.591251Z",
     "start_time": "2020-12-25T16:51:06.564294Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing values: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./input/cleaned/x/12 Comics You Need to See - ...</td>\n",
       "      <td>./input/cleaned/y/12 Comics You Need to See - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./input/cleaned/x/12 Comics You Need to See - ...</td>\n",
       "      <td>./input/cleaned/y/12 Comics You Need to See - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./input/cleaned/x/12 Comics You Need to See - ...</td>\n",
       "      <td>./input/cleaned/y/12 Comics You Need to See - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./input/cleaned/x/12 Comics You Need to See - ...</td>\n",
       "      <td>./input/cleaned/y/12 Comics You Need to See - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./input/cleaned/x/12 Comics You Need to See - ...</td>\n",
       "      <td>./input/cleaned/y/12 Comics You Need to See - ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               input  \\\n",
       "0  ./input/cleaned/x/12 Comics You Need to See - ...   \n",
       "1  ./input/cleaned/x/12 Comics You Need to See - ...   \n",
       "2  ./input/cleaned/x/12 Comics You Need to See - ...   \n",
       "3  ./input/cleaned/x/12 Comics You Need to See - ...   \n",
       "4  ./input/cleaned/x/12 Comics You Need to See - ...   \n",
       "\n",
       "                                              target  \n",
       "0  ./input/cleaned/y/12 Comics You Need to See - ...  \n",
       "1  ./input/cleaned/y/12 Comics You Need to See - ...  \n",
       "2  ./input/cleaned/y/12 Comics You Need to See - ...  \n",
       "3  ./input/cleaned/y/12 Comics You Need to See - ...  \n",
       "4  ./input/cleaned/y/12 Comics You Need to See - ...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_li = pd.Series([input_path + 'x/' + i for i in os.listdir(input_path + 'x/')], dtype=str)\n",
    "# targets have the exact same name, but are in the y/ folder, so to ensure that everything is in the \n",
    "# proper order, list through the input directory, but link to the y/ directory\n",
    "target_li = pd.Series([input_path + 'y/' + i for i in os.listdir(input_path + 'x/')], dtype=str)\n",
    "# table = pd.DataFrame(data=[X, y], columns=['input', 'target'])\n",
    "# table.head()\n",
    "df = pd.DataFrame(data={'input': input_li, 'target': target_li})\n",
    "print(f'missing values: {df.isna().any().sum()}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-25T17:00:43.561152Z",
     "start_time": "2020-12-25T17:00:43.543172Z"
    }
   },
   "outputs": [],
   "source": [
    "class AudioDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, input_path, transform=None):\n",
    "        self.input_path = input_path\n",
    "        # use a root path that branches into x/ and y/ directories\n",
    "        input_li = pd.Series([input_path + 'x/' + i for i in os.listdir(input_path + 'x/')], dtype=str)\n",
    "        # targets have the exact same name, but are in the y/ folder, so to ensure that everything is in the \n",
    "        # proper order, list through the input directory, but link to the y/ directory\n",
    "        target_li = pd.Series([input_path + 'y/' + i for i in os.listdir(input_path + 'x/')], dtype=str)\n",
    "        df = pd.DataFrame(data={'input': input_li, 'target': target_li})\n",
    "        self.df = df.sample(frac=1, random_state=seed)\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        x = self.df['input'].iloc[idx]\n",
    "        x, _ = torchaudio.load(x)\n",
    "        y = self.df['target'].iloc[idx]\n",
    "        y, _ = torchaudio.load(y)\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "            y = self.transform(y)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-25T17:48:37.271045Z",
     "start_time": "2020-12-25T17:48:37.235270Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num samples: 2144\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.1151,  0.1110,  0.1024,  ..., -0.2160, -0.2664, -0.3035],\n",
       "         [ 0.0180,  0.0130,  0.0066,  ..., -0.1551, -0.1982, -0.2359]]),\n",
       " tensor([[ 0.0163,  0.0098,  0.0037,  ..., -0.1633, -0.1965, -0.2296],\n",
       "         [-0.0075, -0.0092, -0.0106,  ..., -0.1255, -0.1577, -0.1906]]))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = AudioDataset(input_path=input_path)\n",
    "print(f'num samples: {len(data)}')\n",
    "x, y = data[0]\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-25T17:56:55.292884Z",
     "start_time": "2020-12-25T17:56:55.276927Z"
    }
   },
   "outputs": [],
   "source": [
    "# loss function\n",
    "def mse(output:torch.Tensor, label:torch.Tensor):\n",
    "    return torch.mean((output - label) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-25T17:57:05.260766Z",
     "start_time": "2020-12-25T17:57:05.242848Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0043)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-25T18:11:25.185274Z",
     "start_time": "2020-12-25T18:11:25.172330Z"
    }
   },
   "outputs": [],
   "source": [
    "# build another loss function, which is based on:\n",
    "# https://openaccess.thecvf.com/content_CVPR_2019/papers/Yuan_Signal-To-Noise_Ratio_A_Robust_Distance_Metric_for_Deep_Metric_Learning_CVPR_2019_paper.pdf\n",
    "# tinyurl:\n",
    "# https://tinyurl.com/yclop5na\n",
    "# this is our implementation\n",
    "class PSNR:\n",
    "    \"\"\"Peak Signal to Noise Ratio\n",
    "    output and target have range [-1, 1]\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.name = \"PSNR\"\n",
    "\n",
    "    @staticmethod\n",
    "    def __call__(output, target):\n",
    "        mse = torch.mean((output - target) ** 2)\n",
    "        return 20 * torch.log10(255.0 / torch.sqrt(mse))\n",
    "\n",
    "class audio_PSNR:\n",
    "    \"\"\"Peak Signal to Noise Ratio\n",
    "    output and target have range [-1, 1]\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.name = \"PSNR\"\n",
    "\n",
    "    @staticmethod\n",
    "    def __call__(output, target):\n",
    "        mse = torch.mean((output - target) ** 2)\n",
    "        return 20 * torch.log10(1.0 / torch.sqrt(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-25T05:02:02.936471Z",
     "start_time": "2020-12-25T05:02:02.919516Z"
    }
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def melspectrogram(self, x):\n",
    "        melspectrogram_transform = transforms.MelSpectrogram(\n",
    "        sample_rate=44100, n_mels=128\n",
    "        )\n",
    "        melspectrogram_db_transform = transforms.AmplitudeToDB()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
