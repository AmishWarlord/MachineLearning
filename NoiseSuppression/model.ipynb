{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T20:26:08.873563Z",
     "start_time": "2020-12-30T20:26:08.835048Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: GeForce GTX 1060 3GB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torchaudio\n",
    "from torchaudio import transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from pydub import AudioSegment\n",
    "torchaudio.USE_SOUNDFILE_LEGACY_INTERFACE = False\n",
    "\n",
    "np.random.seed(seed:=69)\n",
    "torch.manual_seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "current_device = torch.cuda.get_device_name(0) if torch.cuda.device_count() > 0 else 'cpu'\n",
    "print(f'using device: {current_device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T20:23:03.166443Z",
     "start_time": "2020-12-30T20:23:03.163425Z"
    }
   },
   "outputs": [],
   "source": [
    "input_path = './input/cleaned/'\n",
    "output_path = './input/cleaned/output/'\n",
    "sample_rate = 44100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T20:23:03.682778Z",
     "start_time": "2020-12-30T20:23:03.637898Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing values: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./input/cleaned/x/12 Comics You Need to See - ...</td>\n",
       "      <td>./input/cleaned/y/12 Comics You Need to See - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./input/cleaned/x/12 Comics You Need to See - ...</td>\n",
       "      <td>./input/cleaned/y/12 Comics You Need to See - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./input/cleaned/x/12 Comics You Need to See - ...</td>\n",
       "      <td>./input/cleaned/y/12 Comics You Need to See - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./input/cleaned/x/12 Comics You Need to See - ...</td>\n",
       "      <td>./input/cleaned/y/12 Comics You Need to See - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./input/cleaned/x/12 Comics You Need to See - ...</td>\n",
       "      <td>./input/cleaned/y/12 Comics You Need to See - ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               input  \\\n",
       "0  ./input/cleaned/x/12 Comics You Need to See - ...   \n",
       "1  ./input/cleaned/x/12 Comics You Need to See - ...   \n",
       "2  ./input/cleaned/x/12 Comics You Need to See - ...   \n",
       "3  ./input/cleaned/x/12 Comics You Need to See - ...   \n",
       "4  ./input/cleaned/x/12 Comics You Need to See - ...   \n",
       "\n",
       "                                              target  \n",
       "0  ./input/cleaned/y/12 Comics You Need to See - ...  \n",
       "1  ./input/cleaned/y/12 Comics You Need to See - ...  \n",
       "2  ./input/cleaned/y/12 Comics You Need to See - ...  \n",
       "3  ./input/cleaned/y/12 Comics You Need to See - ...  \n",
       "4  ./input/cleaned/y/12 Comics You Need to See - ...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_li = pd.Series([input_path + 'x/' + i for i in os.listdir(input_path + 'x/')], dtype=str)\n",
    "# targets have the exact same name, but are in the y/ folder, so to ensure that everything is in the \n",
    "# proper order, list through the input directory, but link to the y/ directory\n",
    "target_li = pd.Series([input_path + 'y/' + i for i in os.listdir(input_path + 'x/')], dtype=str)\n",
    "# table = pd.DataFrame(data=[X, y], columns=['input', 'target'])\n",
    "# table.head()\n",
    "df = pd.DataFrame(data={'input': input_li, 'target': target_li})\n",
    "print(f'missing values: {df.isna().any().sum()}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T20:23:04.124462Z",
     "start_time": "2020-12-30T20:23:04.105486Z"
    }
   },
   "outputs": [],
   "source": [
    "class AudioDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, input_path, transform=None):\n",
    "        self.input_path = input_path\n",
    "        # use a root path that branches into x/ and y/ directories\n",
    "        input_li = pd.Series([input_path + 'x/' + i for i in os.listdir(input_path + 'x/')], dtype=str)\n",
    "        # targets have the exact same name, but are in the y/ folder, so to ensure that everything is in the \n",
    "        # proper order, list through the input directory, but link to the y/ directory\n",
    "        target_li = pd.Series([input_path + 'y/' + i for i in os.listdir(input_path + 'x/')], dtype=str)\n",
    "        df = pd.DataFrame(data={'input': input_li, 'target': target_li})\n",
    "        self.df = df.sample(frac=1, random_state=seed)\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        x = self.df['input'].iloc[idx]\n",
    "        x, _ = torchaudio.load(x)\n",
    "        y = self.df['target'].iloc[idx]\n",
    "        y, _ = torchaudio.load(y)\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "            y = self.transform(y)\n",
    "        return x, y\n",
    "    \n",
    "    def random(self):\n",
    "        idx = random.randint(0, len(self.df))\n",
    "        return self.__getitem__(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T20:23:04.597777Z",
     "start_time": "2020-12-30T20:23:04.557764Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num samples: 3094\n",
      "2 441000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.0118,  0.0192,  0.0247,  ..., -0.0384, -0.0288, -0.0200],\n",
       "         [ 0.0110,  0.0184,  0.0239,  ..., -0.0472, -0.0322, -0.0175]]),\n",
       " tensor([[-0.0007, -0.0007, -0.0005,  ..., -0.0727, -0.0678, -0.0622],\n",
       "         [-0.0016, -0.0015, -0.0013,  ..., -0.0815, -0.0712, -0.0597]]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = AudioDataset(input_path=input_path)\n",
    "print(f'num samples: {len(data)}')\n",
    "x, y = data[0]\n",
    "input_shape = x.shape\n",
    "flat_feats = input_shape[0] * input_shape[1] \n",
    "print(input_shape[0], input_shape[1])\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T20:23:05.052440Z",
     "start_time": "2020-12-30T20:23:05.041441Z"
    }
   },
   "outputs": [],
   "source": [
    "# loss function\n",
    "def mse(output:torch.Tensor, label:torch.Tensor):\n",
    "    return torch.mean((output - label) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T20:23:05.588657Z",
     "start_time": "2020-12-30T20:23:05.580678Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0012)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T20:23:06.142636Z",
     "start_time": "2020-12-30T20:23:06.134622Z"
    }
   },
   "outputs": [],
   "source": [
    "# build another loss function, which is based on:\n",
    "# https://openaccess.thecvf.com/content_CVPR_2019/papers/Yuan_Signal-To-Noise_Ratio_A_Robust_Distance_Metric_for_Deep_Metric_Learning_CVPR_2019_paper.pdf\n",
    "# tinyurl:\n",
    "# https://tinyurl.com/yclop5na\n",
    "# this is our implementation\n",
    "class PSNR:\n",
    "    \"\"\"Peak Signal to Noise Ratio\n",
    "    output and target have range [0, 255]\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.name = \"PSNR\"\n",
    "\n",
    "    @staticmethod\n",
    "    def __call__(output, target):\n",
    "        mse = torch.mean((output - target) ** 2)\n",
    "        return 20 * torch.log10(255.0 / torch.sqrt(mse))\n",
    "\n",
    "class audio_PSNR:\n",
    "    \"\"\"Peak Signal to Noise Ratio\n",
    "    output and target have range [-1, 1]\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.name = \"audio PSNR\"\n",
    "\n",
    "    @staticmethod\n",
    "    def __call__(output, target):\n",
    "        mse = torch.mean((output - target) ** 2)\n",
    "        return 20 * torch.log10(1.0 / torch.sqrt(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T20:23:06.854828Z",
     "start_time": "2020-12-30T20:23:06.833884Z"
    }
   },
   "outputs": [],
   "source": [
    "class FC_Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.input_shape = self.num_flat_features(x)\n",
    "        super(FC_Net, self).__init__()\n",
    "#         self.conv2d = nn.Conv2d()\n",
    "    \n",
    "    def reshape(self, x):\n",
    "        return torch.unsqueeze(x, 0)\n",
    "    \n",
    "    def melspectrogram(self, x):\n",
    "        melspectrogram_transform = transforms.MelSpectrogram(\n",
    "        sample_rate=44100, n_mels=128\n",
    "        )\n",
    "        melspectrogram_db_transform = transforms.AmplitudeToDB()\n",
    "    \n",
    "    def num_flat_features(self, x) -> int:\n",
    "        size = x.size()[1:] # all dims except batch dim\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return int(num_features)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.reshape(x)\n",
    "        x = f.relu(self.fc1(x))\n",
    "#         x = f.relu(self.fc3(x))\n",
    "        x = torch.reshape(x, self.input_shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T20:23:07.404847Z",
     "start_time": "2020-12-30T20:23:07.389916Z"
    }
   },
   "outputs": [],
   "source": [
    "net = FC_Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T20:23:08.159917Z",
     "start_time": "2020-12-30T20:23:08.144958Z"
    }
   },
   "outputs": [],
   "source": [
    "# melspectogram_transform = \\\n",
    "#     torchaudio.transforms.MelSpectrogram(\n",
    "#     sample_rate=sample_rate, n_mels=128)\n",
    "# melspectogram_db_transform = torchaudio.transforms.AmplitudeToDB()\n",
    "\n",
    "# melspectogram = melspectogram_transform(audio)\n",
    "# plt.figure()\n",
    "# plt.imshow(melspectogram.squeeze().numpy(), cmap='hot')\n",
    "    \n",
    "# melspectogram_db=melspectogram_db_transform(melspectogram)\n",
    "# plt.figure()\n",
    "# plt.imshow(melspectogram_db.squeeze().numpy(), cmap='hot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T20:25:25.796276Z",
     "start_time": "2020-12-30T20:25:25.253344Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "441\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1846,  0.3150, -0.0348,  ..., -0.1916, -0.0395, -0.0168],\n",
       "         [-0.0936,  0.2930, -0.3092,  ...,  0.3404,  0.3235, -0.4412]]],\n",
       "       grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(int(x.shape[1] / 1000))\n",
    "p = torch.randn((1, 1, 2, int(x.shape[1] / 1000)))\n",
    "m = nn.Conv2d(1, 16, kernel_size=2)\n",
    "p = m(p)\n",
    "p = torch.flatten(p)\n",
    "p = nn.Linear(p.nelement(), p.nelement() * 2)(p)\n",
    "p = torch.reshape(p, (1, 2, -1))\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T20:26:56.184851Z",
     "start_time": "2020-12-30T20:26:56.156744Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'seek'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\pydub\\audio_segment.py\u001b[0m in \u001b[0;36mfrom_file\u001b[1;34m(cls, file, format, codec, parameters, **kwargs)\u001b[0m\n\u001b[0;32m    627\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 628\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_from_safe_wav\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    629\u001b[0m             \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\pydub\\audio_segment.py\u001b[0m in \u001b[0;36m_from_safe_wav\u001b[1;34m(cls, file)\u001b[0m\n\u001b[0;32m    737\u001b[0m         \u001b[0mfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_fd_or_path_or_tempfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtempfile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 738\u001b[1;33m         \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    739\u001b[0m         \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'seek'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-9f59267c8553>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mAudioSegment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_wav\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\pydub\\audio_segment.py\u001b[0m in \u001b[0;36mfrom_wav\u001b[1;34m(cls, file, parameters)\u001b[0m\n\u001b[0;32m    726\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfrom_wav\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 728\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wav'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    729\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\pydub\\audio_segment.py\u001b[0m in \u001b[0;36mfrom_file\u001b[1;34m(cls, file, format, codec, parameters, **kwargs)\u001b[0m\n\u001b[0;32m    628\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_from_safe_wav\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    629\u001b[0m             \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 630\u001b[1;33m                 \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    631\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"raw\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mis_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"pcm\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    632\u001b[0m             \u001b[0msample_width\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sample_width'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'seek'"
     ]
    }
   ],
   "source": [
    "torchaudio.save('amazing_sound.wav', sound, sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
